{
  "metadata": {
    "input_documents": [
      "1480-9222-11-1-9004.pdf",
      "All_biology_is_computational_biology.pdf",
      "file.pdf"
    ],
    "persona": "PhD Researcher in Computational Biology",
    "job_to_be_done": "Prepare a literature review focusing on methodologies, datasets, and performance benchmarks",
    "timestamp": "2025-07-28T06:53:58.542878Z"
  },
  "extracted_sections": [
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 3,
      "section_title": "important parts might even be missing and waiting for discov",
      "importance_rank": 1
    },
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 1,
      "section_title": "RESEARCH MATTERS",
      "importance_rank": 2
    },
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 2,
      "section_title": "In the following, I will argue that computational thinking a",
      "importance_rank": 3
    },
    {
      "document": "file.pdf",
      "page_number": 1,
      "section_title": "EDITORIAL",
      "importance_rank": 4
    },
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 4,
      "section_title": "But how exactly can you measure \u201cgenetic heterogeneity,\u201d and",
      "importance_rank": 5
    },
    {
      "document": "file.pdf",
      "page_number": 3,
      "section_title": "information about the structure, development, and function o",
      "importance_rank": 6
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 27,
      "section_title": "Yaschenko E. (2008) Database resources",
      "importance_rank": 7
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 3,
      "section_title": "the number of completed genomes will be in the order of doub",
      "importance_rank": 8
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 6,
      "section_title": "der. Information is already known about the order of each su",
      "importance_rank": 9
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 9,
      "section_title": "carried out on each project into account. Comparisons carrie",
      "importance_rank": 10
    }
  ],
  "subsection_analysis": [
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 3,
      "refined_text": "important parts might even be missing and waiting for discovery. \u201cHere be dragons,\u201d it just\nsays. But even with all these shortcomings, the map is still an indispensable guide: the atlas of\nlife provided by computational biology forms the background for planning, executing, and\ninterpreting all focussed small-scale experiments that probe the uncharted areas and push out\nthe boundaries of biological knowledge.\nComputational biology turns ideas into hypotheses\nFinally, computers reshaped biology by making fuzzy concepts rigorous and testable. Here is\none example from my own research: for decades, cancer researchers have discussed the idea\nthat genetic heterogeneity between cells in the same tumour helps to make a cancer resistant to\ntherapy [6]. It is a simple idea: the more diverse the cell population is, the more likely it is that\na subset of the cells is resistant to therapy and can regrow the tumour after all other cells were\nkilled.\nFig 1. Carl von Linne\u00b4, the Swedish botanist and father of taxonomy, would be a computational\nbiologist today. Image credit: Nationalmuseum Stockholm.\ndoi:10.1371/journal.pbio.2002050.g001\nPLOS Biology | DOI:10.1371/journal.pbio.2002050\nMarch 9, 2017\n3 / 4"
    },
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 1,
      "refined_text": "RESEARCH MATTERS\nAll biology is computational biology\nFlorian Markowetz*\nUniversity of Cambridge, Cancer Research UK Cambridge Institute, Cambridge, United Kingdom\n* florian.markowetz@cruk.cam.ac.uk\nAbstract\nHere, I argue that computational thinking and techniques are so central to the quest of\nunderstanding life that today all biology is computational biology. Computational biology\nbrings order into our understanding of life, it makes biological concepts rigorous and test-\nable, and it provides a reference map that holds together individual insights. The next mod-\nern synthesis in biology will be driven by mathematical, statistical, and computational\nmethods being absorbed into mainstream biological training, turning biology into a quantita-\ntive science.\n\u201cHow do people like you ever get last-author papers?\u201d A leading cell biologist asked me this\nquestion in 2008 during the interview for my current job, implying I could never take a senior\nrole in research projects. I had been trained in mathematics and machine learning but was\nnow interviewing for a computational biology job in a cancer research institute. My inter-\nviewer wasn\u2019t really sure what my contribution to biology could ever be. Aren\u2019t computational\nfolks just service providers? Handy to have, but without any real scientific vision? She clearly\nworried about my ability to do independent biological research.\nAnd she was not the last to worry. In 2012, with several last-author papers to my name, I\nwas shortlisted for an European Molecular Biology Organization Young Investigator fellow-\nship but did not get it. The feedback provided by the interview panel called my group a \u201cmath-\nematical service unit,\u201d claimed \u201ca lack of in-depth understanding of biology,\u201d and decried \u201can\noverly strong reliance on collaborators.\u201d\nLast year, we finally saw how low the opinion of computational work really can be in the\nbiomedical community, when the editor-in-chief of the New England Journal of Medicine\nused the term \u201cresearch parasites\u201d to describe computational biologists making sense of pub-\nlished data [1].\nOver the last 20 years, computational methods have become a well-established part of biol-\nogy, but the examples above show that \u201cold school\u201d biologists and clinicians\u2014who make deci-\nsions on publications, funding, and careers\u2014continue to be uncomfortable with people like\nme, who were trained in other disciplines, pursue biological questions different from their\nown, and use approaches not covered in most biological training. If even my colleagues in the\nlife sciences do not see why computational research matters, how will anybody else be able to\nsee its worth?\nPLOS Biology | DOI:10.1371/journal.pbio.2002050\nMarch 9, 2017\n1 / 4\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Markowetz F (2017) All biology is\ncomputational biology. PLoS Biol 15(3): e2002050.\ndoi:10.1371/journal.pbio.2002050\nPublished: March 9, 2017\nCopyright: \u00a9 2017 Florian Markowetz. This is an\nopen access article distributed under the terms of\nthe Creative Commons Attribution License, which\npermits unrestricted use, distribution, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nFunding: Cancer Research UK http://www.\ncancerresearchuk.org/ (grant number C14303/\nA17197). The funder had no role in study design,\ndata collection and analysis, decision to publish, or\npreparation of the manuscript.\nCompeting interests: The authors have declared\nthat no competing interests exist.\nProvenance: Commissioned; not externally peer\nreviewed"
    },
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 2,
      "refined_text": "In the following, I will argue that computational thinking and computational methods are\nso central to the quest of understanding life that today all biology is computational biology.\nComputational biology brings order into our understanding of life\n\u201c[B]iology adapted itself to the computer, not the computer to biology,\u201d writes Hallam Stevens\nin Life Out of Sequence [2], his ethnographic and historical account of computational biology.\nHe explains: \u201cComputers do not just scale up the old biology, they bring with them completely\nnew tools and questions, like statistics, simulation, and data management, that completely re-\nshaped the way biological research is being done.\u201d\nOne key example of how computers reshaped biological research is the use of databases and\nontologies. Biological knowledge today is defined, organised, and accessed through computa-\ntion. If Carl von Linne\u00b4 (also known as Carl Linnaeus), the Swedish botanist and father of tax-\nonomy, lived today, he would be a computational biologist (Fig 1). As a botanist, he might take\na leading role in a project like transPLANT (http://www.transplantdb.eu/) to organise what we\nknow about the genotypes and phenotypes of crops and model plants. Or he might work with\nthe Gene Ontology Consortium (http://www.geneontology.org/) to create shared vocabularies\nthat unify biological knowledge across organisms. Just like Linne\u00b4\u2019s Systema Naturae, such data-\nbases are key intellectual contributions to our understanding of life. Every other type of biolog-\nical research builds on these foundations.\nComputational biology lets you see the big picture\nAnother way computers have reshaped biology is by introducing statistics and data analysis\nmethods. A good example is understanding how mutational processes shape genomes [3].\nMutational processes\u2014be it cigarette smoke, sunlight, or defects in homologous recombina-\ntion\u2014are not visible in individual mutations but only in their global patterns. How often is a C\nturned into a T? How does this frequency vary depending on the neighbours of the mutated\nbase? How much of this frequency is explained by other features of the genome, like replica-\ntion timing? Answering these questions helps us to understand basic properties of the muta-\ntional processes active in cells, and it is only possible by statistical techniques that identify\npatterns and correlations.\nThese types of analyses need large data collections, and thus the success of computational\nbiology is closely linked to the success of large-scale efforts to gather genotypes and phenotypes\nof model organisms and humans. One of the first examples highlighting the power of computa-\ntional approaches was sequencing the human genome, which showed how efficiently computa-\ntional alignment and scaffolding methods were able to assemble the DNA fragments produced\nduring shotgun sequencing [4], and modern Next Generation Sequencing techniques completely\nrely on advances in computational biology to analyse huge amounts of short sequence reads [5].\nDNA sequencing was once a Nobel Prize\u2013worthy development. Now, computational biology is\nleading the way in turning it into a widely available and practical approach for both basic biology\nand medical research, which is currently revolutionising what we know about tissues and single\ncells.\nComputational biology provides an atlas of life\nBy combining large data collections with databases and statistics, computational biology is\nproviding a reference map for biology\u2014an atlas of life that holds together individual insights.\nThis map is not at the level of resolution provided by Google Street View, rather, it is a map\nlike the one used by Columbus, Magellan, or Vasco da Gama\u2014intrepid explorers in search\nof adventure. The map provides a general outline, but many areas are sketchy, and some\nPLOS Biology | DOI:10.1371/journal.pbio.2002050\nMarch 9, 2017\n2 / 4"
    },
    {
      "document": "file.pdf",
      "page_number": 1,
      "refined_text": "EDITORIAL\nFrom \u201cWhat Is?\u201d to \u201cWhat Isn't?\u201d\nComputational Biology\nRuth Nussinov1,2*, Sebastian Bonhoeffer3, Jason A. Papin4, Olaf Sporns5\n1 Cancer and Inflammation Program, Leidos Biomedical Research, Inc., Frederick National Laboratory for\nCancer Research, National Cancer Institute, Frederick, Maryland, United States of America, 2 Sackler\nInstitute of Molecular Medicine, Department of Human Genetics and Molecular Medicine, Sackler School of\nMedicine, Tel Aviv University, Tel Aviv, Israel, 3 Theoretical Biology Group, Institute of Integrative Biology,\nETH Zurich, Zurich, Switzerland, 4 Department of Biomedical Engineering, University of Virginia,\nCharlottesville, Virginia, United States of America, 5 Department of Psychological and Brain Sciences,\nIndiana University, Bloomington, Indiana, United States of America\n* nussinor@helix.nih.gov\nThis year, PLOS Computational Biology is celebrating its 10th birthday. Such a milestone pro-\nvides an excellent occasion to reflect on the transformation that the field has undergone during\nthe journal\u2019s lifetime, and on the challenging question of where we may expect it to go next. As\nthe leading journal in computational biology, PLOS Computational Biology encompasses the\nentire discipline and is therefore well placed to narrate this remarkable story. The evolution of\nthe journal tells a rewarding story of success and accomplishment.\nComputational biology has forged ahead, branching into every field of the biological sci-\nences, and has become an integral part of basic biological research from molecules to ecosys-\ntems. We are no longer asking, \"What is computational biology?\u201d Instead, glancing over recent\npublications in PLOS Computational Biology, a more apt question is, \u201cIs there any area of biol-\nogy that doesn\u2019t involve computational biology?\u201d Indeed, nowadays most life science depart-\nments search for and hire faculty whose research embraces sophisticated approaches to\ncomputational biology. Increasingly, graduate training programs include computational\nmodeling and data analysis as integral parts of the curriculum. This reflects not only the scien-\ntific merit of a mature field; it also points to a wider recognition that a background in computa-\ntional biology is becoming mandatory. Students need to have solid training in computations.\nWhat will we be able to accomplish in the next ten years that we were not able to achieve\nover the last ten? The explosion in computational biology has been driven by the rapid increase\nin the availability of experimental data and computational power. Both were, and will continue\nto be, revolutionized; both promise to keep transforming cutting-edge computational biology.\n\u201cBig data\u201d is a recurring theme, and as the volume of data continues to increase, there will be a\ngrowing need for computational tools and techniques to convert \u201cbig data\u201d into biological\nknowledge, a challenge supported by the National Institutes of Health via the BD2K grants\nlaunched in 2012.\nFirstly, the next decade will very likely be more data-intensive than the last decade. Biologi-\ncal data will increasingly be quantitative, substituting and supplementing traditional, descrip-\ntive biology. Examples (chosen for illustrative purposes) include identifying, cataloging, and\nanalyzing microbes populating different tissues, ages, and health states, as well as microbes\nresiding in the soil or in the ocean in specific environments where they can be useful, for\nexample, against oil spills; discovering and classifying parallel cellular pathways that activate\noverlapping (or distinct) functions, for example, those emanating from the same family of\nPLOS Computational Biology | DOI:10.1371/journal.pcbi.1004318\nJuly 2, 2015\n1 / 3\nOPEN ACCESS\nCitation: Nussinov R, Bonhoeffer S, Papin JA,\nSporns O (2015) From \u201cWhat Is?\u201d to \u201cWhat Isn't?\u201d\nComputational Biology. PLoS Comput Biol 11(7):\ne1004318. doi:10.1371/journal.pcbi.1004318\nPublished: July 2, 2015\nCopyright: This is an open access article, free of all\ncopyright, and may be freely reproduced, distributed,\ntransmitted, modified, built upon, or otherwise used\nby anyone for any lawful purpose. The work is made\navailable under the Creative Commons CC0 public\ndomain dedication.\nFunding: The authors received no specific funding\nfor this article.\nCompeting Interests: Ruth Nussinov is the Editor-\nin-Chief of PLOS Computational Biology. Sebastian\nBonhoeffer, Jason Papin, and Olaf Sporns are the\nDeputy Editors-in-Chief of PLOS Computational\nBiology."
    },
    {
      "document": "All_biology_is_computational_biology.pdf",
      "page_number": 4,
      "refined_text": "But how exactly can you measure \u201cgenetic heterogeneity,\u201d and how big is its influence on\nresistance development? To answer these questions, we had to turn the idea into a testable\nhypothesis. We used genomic approaches to measure changes in cancer genomes at different\nsites in a patient and then defined quantitative measures of heterogeneity, which could be\ncompared statistically to clinical information on treatment resistance. And indeed, we found\nevidence supporting the initial idea that heterogeneity determines resistance [7].\nThis is just one of many examples in which a quantitative computational approach was\nneeded to turn a fuzzy idea into a testable hypothesis. Computational biology excels at distill-\ning huge amounts of complex data into something testable in the wet lab, thus, shaping and\ndirecting experimental follow-up.\nRest in peace, computational biology\nPipette biologist. Microscopy biologist. Cell culture biologist. Have you ever heard any of\nthose job titles? No, of course not. All are biologists, because it is the questions you address\nthat matter, not the tools you use, and computational biologists are just biologists using a dif-\nferent tool.\nThe next modern synthesis in biology will be driven by the absorption of mathematical, sta-\ntistical, and computational methods into mainstream biological training. It will look more and\nmore like training in physics and combine teaching experimental techniques with mathemati-\ncal theory and data analysis. And then, even \"old school\" biologists will view computational\nbiologists as one of their own.\nReferences\n1.\nLongo D.L. and Drazen J.M., Editorial Data Sharing, N Engl J Med 2016; 374:276\u2013277 doi: 10.1056/\nNEJMe1516564 PMID: 26789876\n2.\nStevens Hallam, Life Out of Sequence: A Data-Driven History of Bioinformatics, The University of Chi-\ncago Press; 2013\n3.\nAlexandrov L. B. et al. Signatures of mutational processes in human cancers. Nature 2013 Aug 22; 500\n(7463): 415\u2013421. doi: 10.1038/nature12477 PMID: 23945592\n4.\nWeber J.L. and Myers E.W. Human whole-genome shotgun sequencing. Genome Res. 1997 May; 7\n(5):401\u20139. PMID: 9149936\n5.\nFlicek P. and Birney E. Sense from sequence reads: methods for alignment and assembly. Nat Meth-\nods. 2009 Nov; 6(11 Suppl):S6\u2013S12. doi: 10.1038/nmeth.1376 PMID: 19844229\n6.\nNowell P.C. The clonal evolution of tumor cell populations. Science. 1976 Oct 1; 194(4260):23\u20138.\nPMID: 959840\n7.\nSchwarz R.F. et al. Spatial and temporal heterogeneity in high-grade serous ovarian cancer: a phyloge-\nnetic analysis. PLoS Med. 2015 Feb 24; 12(2):e1001789. doi: 10.1371/journal.pmed.1001789 PMID:\n25710373\nPLOS Biology | DOI:10.1371/journal.pbio.2002050\nMarch 9, 2017\n4 / 4"
    },
    {
      "document": "file.pdf",
      "page_number": 3,
      "refined_text": "information about the structure, development, and function of the brain has grown, so has the\nneed to exploit them to advance basic scientific insight. Development of capable computational\nmethods that can be applied across diverse types of data is critical and forms an integral part of\ncomputational (neuro)biology. These require not only advanced computing power; they also\nincreasingly demand integration of data across different domains (e.g., genomics, physiology,\nbehavior) and levels of biological organization (cells, circuits, systems) into a single analytic or\nmodeling framework.\nOn their own, neither computations nor experiments can overcome these pressing chal-\nlenges. Our current computational power can only simulate a small fraction of the time scale of\nbiological processes, and it is limited to a tiny portion of the real molecular complex in a cellu-\nlar environment. To mention just one example, the complete conformational change of the R\nto T transition in hemoglobin occurs in tens of microseconds. Using current resources, our\nlarge-scale simulations of a small protein can only account for processes covering microsec-\nonds. To effectively complement experimental studies, the time and spatial scales covered in\ncomputational biological models must continue to grow, beyond our current capabilities. Only\nexascale computing can meet the pressing challenges facing the biological sciences. Exascale\ncomputing, capable of at least one exaFLOPS, or a billion billion calculations per second, repre-\nsents a 1,000-fold increase over the first 2008 petascale computer. While the National Institutes\nof Health is currently considering the possibilities of insights to be gained based on future\ncomputational resources, exploiting such power, estimated to become available in 2018 (at the\nearliest), may\u2014under the best of circumstances\u2014only be realized a decade from now.\nFinally, PLOS Computational Biology is a community journal, championing the open access\nparadigm. Within this framework, we believe in data and software sharing. This has always\nbeen of paramount importance; with the unprecedented advancement of the field and its diver-\nsified disciplines, open data and software will become even more critical to drive further revo-\nlutions and to enlist participation from across the globe. No one knows what the future will\nbring\u2014but it seems certain that the future is not going to be less computational; instead it is\nlikely that computational analysis, tools, and models will become seamlessly integrated into the\nwider field of biology. In parallel with the inevitable expansion of biological data, computa-\ntional biology will be indispensable for developing tools and approaches that are robust against\nnoise and statistical biases, for devising testable and predictive models, and for delivering quan-\ntitative insight into fundamental biological processes within and across scales of organization.\nPLOS Computational Biology has been part of the field from its infancy, when questions such\nas, \"What is computational biology?\" were common, through to today, when, \"What isn't\ncomputational biology?\u201d seems far more appropriate. Together with the International Society\nfor Computational Biology (ISCB) community and our broad and increasing readership, the\njournal will continue to serve as a forum for all aspects of computational biology, leading the\ndiscipline into its next decade.\nPLOS Computational Biology | DOI:10.1371/journal.pcbi.1004318\nJuly 2, 2015\n3 / 3"
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 27,
      "refined_text": "Yaschenko E. (2008) Database resources\nof the National Center for Biotechnology\nInformation. Nucleic Acids Res 36(Data-\nbase issue), D13\u2013D21.\n74. Peterson J. D., Umayam L. A., Dickinson\nT., Hickey E. K., White O. (2001) The\nComprehensive Microbial Resource.\nNucleic Acids Res 29(1), 123\u2013125.\n75. Choi K., Ma Y., Choi J. H., Kim S. (2005)\nPLATCOM: a Platform for Computational\nComparative Genomics. Bioinformatics 21\n(10), 2514\u20132516.\n76. Toft C., Fares M. A. (2006) GRAST: a new\nway of genome reduction analysis using\ncomparative genomics. Bioinformatics 22\n(13), 1551\u20131561.\n77. Xie T., Hood L. (2003) ACGT\u2014a compar-\native genomics tool. Bioinformatics 19(8),\n1039\u20131040.\n78. Chen T., Abbey K., Deng W. J., Cheng M.\nC. (2005) The bioinformatics resource for\noral pathogens. Nucleic Acids Res 33(Web\nServer issue), W734\u2013W740.\n79. Leader D. P. (2004) BugView: a browser\nfor comparing genomes. Bioinformatics 20\n(1), 129\u2013130.\n80. Yang J., Wang J., Yao Z. J., Jin Q., Shen Y.,\nChen R. (2003) GenomeComp: a visualiza-\ntion tool for microbial genome comparison.\nJ Microbiol Methods 54(3), 423\u2013426.\n81. Romualdi A., Felder M., Rose D., Gausmann\nU., Schilhabel M., Glockner G., Platzer M.,\nSuhnel J. (2007) GenColors: annotation\nand comparative genomics of prokaryotes\nmade easy. Methods Mol Biol 395, 75\u201396.\n82. Grant J. R., Stothard P. (2008) The\nCGView Server: a comparative genomics\ntool for circular genomes. Nucleic Acids\nRes 36, W181\u2013W184.\n83. Ghai R., Chakraborty T. (2007) Compara-\ntive microbial genome visualization using\nGenomeViz. Methods Mol Biol 395, 97\u2013\n108.\n84. Dubchak I., Ryaboy D. V. (2006) VISTA\nfamily of computational tools for compara-\ntive analysis of DNA sequences and whole\ngenomes. Methods Mol Biol 338, 69\u201389.\n85. Hohl M., Kurtz S., Ohlebusch E. (2002)\nEfficient multiple genome alignment. Bio-\ninformatics 18(Suppl 1), S312\u2013S320.\n86. Treangen T. J., Messeguer X. (2006) M-\nGCAT: interactively and efficiently\nconstructing large-scale multiple genome\ncomparison frameworks in closely related\nspecies. BMC Bioinformatics 7, 433.\n87. Darling A. C., Mau B., Blattner F. R.,\nPerna N. T. (2004) Mauve: multiple align-\nment of conserved genomic sequence with\nrearrangements. Genome Res 14(7), 1394\u2013\n1403.\n88. Tzika A. C., Helaers R., Van de Peer Y.,\nMilinkovitch M. C. (2008) MANTIS: a\nphylogenetic framework for multi-species\ngenome comparisons. Bioinformatics 24\n(2), 151\u2013157.\n89. Andersson S. G., Kurland C. G. (1998) Re-\nductive evolution of resident genomes.\nTrends Microbiol 6(7), 263\u2013268.\n90. Oliver K. M., Russell J. A., Moran N. A.,\nHunter M. S. (2003) Facultative bacterial\nsymbionts in aphids confer resistance to\nparasitic wasps. Proc Natl Acad Sci USA\n100(4), 1803\u20131807.\n91. Bensadia F., Boudreault S., Guay J. F.,\nMichaud D., Cloutier C. (2006) Aphid\nclonal resistance to a parasitoid fails under\nheat stress. J Insect Physiol 52(2), 146\u2013\n157.\n92. Degnan P. H., Moran N. A. (2008) Evolu-\ntionary genetics of a defensive facultative\nsymbiont of insects: exchange of toxin-\nencoding bacteriophage. Mol Ecol 17(3),\n916\u2013929.\n93. Douglas A. E. (1996) Reproductive failure\nand the free amino acid pools in pea aphids\n(Acyrthosiphon pisum) lacking symbiotic\nbacteria. J Insect Physiol 42(3), 247\u2013255.\n94. Buchner P. (1965) Endosymbiosis of ani-\nmals with plant microorganisms. Inter-\nscience, New York., NY.\n95. Muller H. J. (1964) The relation of recom-\nbination to mutation advance. Mutat Res 1,\n2\u20139.\n96. Perez-Brocal V., Gil R., Ramos S., Lamelas\nA., Postigo M., Michelena J. M., Silva F. J.,\nMoya A., Latorre A. (2006) A small mi-\ncrobial genome: the end of a long symbiot-\nic relationship? Science 314(5797), 312\u2013\n313.\n97. Koonin E. V. (2000) How many genes can\nmake a cell: the minimal-gene-set concept.\nAnnu Rev Genomics Hum Genet 1, 99\u2013\n116.\n98. Gerdes S. Y., Scholle M. D., Campbell J. W.,\nBalazsi G., Ravasz E., Daugherty M. D.,\nSomera A. L., Kyrpides N. C., Anderson I.,\nGelfand M. S., Bhattacharya A., Kapatral\nV., D'Souza M., Baev M. V., Grechkin Y.,\nMseeh F., Fonstein M. Y., Overbeek R.,\nBarabasi A. L., Oltvai Z. N., Osterman\nA. L. (2003) Experimental determination\nand system level analysis of essential genes\nin Escherichia coli MG1655. J Bacteriol\n185(19), 5673\u20135684.\nComparative Genomics of Endocellular Symbiotic Bacteria\n77"
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 3,
      "refined_text": "the number of completed genomes will be in the order of double\nthat by the end of 2009 with a considerable percentage of these al-\nready published in the literature. Already the Entrez Genome proj-\nect website controlled by National Center for Biotechnology\nInformation (NCBI) reports that on February 3, 2009, 857\ngenomes are complete, 815 are in draft assembly, and 989 are in\nprogress (http://www.ncbi.nlm.nih.gov/genomes/static/gpstat.\nhtml). The number of institutes worldwide with increasing se-\nquencing capacities has been rising at an exponential rate and\nthe first results of analyzing such data have solved old and long\ndebated hypotheses and also have generated breakthrough ideas\nthat have opened new avenues in all fields of genetics and evolu-\ntionary biology. However, our ability to cope technically with\nthe amount of generated raw data has become seriously compro-\nmised, fueling many initiatives aimed at developing computa-\ntional tools to analyze genomic and proteomic data. Many of\nthese tools have been developed to perform comparative ge-\nnomic analyses; each tool has had to face many of the complex-\nities that biologically driven genome remodeling phenomena\ncause, such as genome duplication, rearrangement, and shrink-\nage. In this review, we first discuss the different technologies de-\nveloped to perform genomic and proteomic analyses. We then\nfocus on the importance of the developed tools to study biolog-\nically important phenomena such as genome duplication, the dy-\nnamics of genome rearrangement, and genome shrinkage that is\nassociated with the intracellular life of bacteria.\n2. Common Meth-\nods in Compara-\ntive Genomics\nComparative genomic methods are vast in number as well as func-\ntion. A decision about the best way to do something is often a long\nand arduous task in this field, a task that has resulted in the design\nand reengineering of many of the tools that are available. To de-\nscribe every method in this area of research would be next to im-\npossible, and so, this text will provide a snapshot of what is\navailable for many of the common tasks in comparative genomics.\nThe logical place to start is of course the beginning\u2014genome se-\nquencing, assembly, and closing, then continuing to discuss the in-\ntricacies of comparative genomics.\nWhile in the past comparative genomics has concentrated on\nsequencing single genomes and parts of genomes, current excite-\nment lies with the sequencing of environmental communities.\nThis field of research, entitled metagenomics is fast growing and\nthe current hot topic. Its application is most utilized to character-\nComparative Genomics of Endocellular Symbiotic Bacteria\n53"
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 6,
      "refined_text": "der. Information is already known about the order of each subset\nof reads and thus less error is incurred in the final assembly. Of\ncourse, there are disadvantages with each of these approaches.\nFor instance, with the whole-genome approach, there is the un-\ncertainty as to whether the assembly is correct due to the total\nreliance on bioinformatics tools to join and order the reads; in\naddition, coverage may be insufficient (i.e., overlap between\nthe fragments). The second approach is time consuming and la-\nbor intensive due to the addition of the extra step at the begin-\nning of the protocol (10); this approach is also susceptible to\nincomplete coverage (11). Further advances have been made\nsince the advent of shotgun sequencing but the central concepts\nremain the same.\nTechnologies currently used in genome sequencing include\nhigh-throughput methods such as 454 (12), SOLid (Applied Bio-\nsciences), and Solexa (13). These methods differ from older tech-\nnologies in their throughput. Hundreds of thousands of DNA\nmolecules at the same time are sequenced instead of a single\nDNA clones being processed (14). The reads returned from each\nof these technologies are very short; thus, assembly is rather diffi-\ncult. This disadvantage is offset by the fact that some much DNA\nis sequenced. The sequencing methodology of these approaches,\nin particular 454, is called pyrosequencing. This essentially is the\nsequencing of DNA utilizing the detection of enzymatic activity\nto identify the bases. This process is termed \u201csequencing-by-\nsynthesis\u201d (15). Future developments will of course increase the\nlength of reads produced by the technologies, as well as the accu-\nracy of the programs with which the fragments are assembled.\nDiscussion in the past has provided some insight into the pit-\nfalls of each method and perhaps aided in the decision making\nprocess (14, 16, 17). One thing is certain, the higher the cover-\nage the method is able to achieve, the higher the likelihood that\nthe assembly tool will get the correct result and so that in itself\nshould be one of the highest considerations in the decision mak-\ning process.\n4. Base Calling\nand Genome\nAssembly\nAfter genome sequencing is complete, it then becomes necessary to\nreconstruct the sequence fragments into a meaningful order that\nwill accurately reflect the original orientation and order of the gene\nand junk (noncoding regions and pseudogenes) content. The most\ncommon and popular manner in which this is achieved is through\nthe Phred (18, 19)\u2013PHRAP (20)\u2013CONSED (21) pipeline of tools\n56\nJ. Commins et al."
    },
    {
      "document": "1480-9222-11-1-9004.pdf",
      "page_number": 9,
      "refined_text": "carried out on each project into account. Comparisons carried out\nby groups such as Huang and Madan (33) and Chen and Skiena\n(34) are works that seek to validate recently released methods.\nChen and Skiena (34) come closest to an objective comparison\nin their rigorous testing of their own creation, STROLL, and lat-\nest versions (at the time) of PHRAP by Green (20) and the TIGR\nAssembler by Sutton et al. (23). In their evaluation of the pro-\ngrams, they reported that PHRAP was consistently more accurate\nin producing the correct assembly and had the lowest error rates\nof the group. STROLL produced similar results to PHRAP while\nTIGR Assembler produced a considerably more erroneous resul-\ntant assembly. The TIGR Assembler produced significantly more\nand smaller contigs, a higher proportion of gaps remaining un-\nclosed and aside from the result, the process of running the\nTIGR Assembler on the read data used took approximately five\ntimes longer to complete than either of the other two programs\nevaluated.\nIn the race to publish the Human genome in the early 2000s,\nthe Celera Whole Genome Assembler was engineered to accom-\nmodate large genomes. Its first use was described by (24) in the\npaper reporting the completion of the Drosophila genome (Myers\net al.). This was enhanced and used later in the initial assembly of\nthe Human genome (35) and the publication of the whole human\ngenome assembly (36) in addition to the mouse (37), dog (38),\nand mosquito (39) genomes. While Celera is a private corpora-\ntion, it has released the Celera Assembler as open source software\nfor free usage.\nIn early 2007, a new assembly algorithm was described by\nSommer et al. (25). It is a streamlined approach aimed at provid-\ning a simple, faster, and more efficient means of assembling frag-\nmented sequences. Minimus (25) performs its best on small\nassembly jobs such as small genomes, genes, and bacterial artificial\nchromosome clones (40). It has also been assessed with respect\nto assembling larger sets of fragmented DNA such as those\nfound in bacterial genomes and has been found to produce\nfewer assembly errors than PHRAP. The cost of this reduction\nin error rate is that the number of contigs is greater and con-\nsequently, the size of the contigs is smaller, resulting in a more\nfragmented assembly (25). In addition, all test assemblies pro-\nduced by Minimus were completed in approximately half the\ntime that PHRAP used. It remains to be seen whether this\nnew assembler will work its way into common use in assembly\nsystems such as Phusion and Atlas, but it is unlikely to remain\nat an advantage for long as the development and advancements\nof new and reworked as assemblers is swift and continuous. It\nhas been suggested that it is beneficial for more than one\nmethod to be used, so that the exclusive advantages of each\nmethod may be exploited (33). This strategy may well of\nComparative Genomics of Endocellular Symbiotic Bacteria\n59"
    }
  ]
}